# AAIE Data Model

This document explains the **Entity–Relationship Diagram (ERD)** for the AAIE system.  
It highlights the **current MVP (Trimester 2 scope)** and the **planned future extensions** for the platform.  

---


## 🎯 MVP Scope (Trimester 2)

The following entities are implemented in the **MVP release**:

- **User**  
  Represents system participants (students, educators).  
  Stores identity and role, which determine system permissions.

- **Prompt**  
  Academic task or assignment created by an educator (or submitted by a student).  
  Linked to the user who created it.  
  Includes fields for `use_case` and `source`.

- **StudentResponse**  
  Stores the student’s submission to a prompt.  
  Includes metadata such as version, status, submission timestamp, and uniqueness (`user_id + prompt_id + is_current=true`).

- **RubricScore**  
  Evaluator’s rubric-based grading of a student response.  
  Includes structure, clarity, relevance scores, and evaluator info.

- **Feedback**  
  Contains written feedback (human + LLM-generated), suggestions, and encouraging notes linked to a response.

- **ResponseHistory** *(optional)*  
  Stores archived versions of student submissions for traceability.

- **ChatLog**  
  Stores the GenAI conversation log submitted by the student for accountability and integrity tracking.

---

## 🔮 Future Scope

The following entities are **planned for future releases** but not part of the MVP:

- **AIContentScore**  
  Automated scoring generated by an AI model (0–100 scale).  
  Complements human rubric scoring.

- **SimilarityScore**  
  Measures similarity between student submissions and AI-generated outputs.  
  If similarity ≥ 40%, the response may be flagged for resubmission.

- **BiasTracking**  
  Planned feature to monitor evaluator fairness and potential scoring inconsistencies.

---

## 📖 Relationship to System Documents

- **Software Requirements Specification (SRS)** → Defines how each entity supports user requirements.  
- **API Proposal** → Specifies endpoints to manage Users, Prompts, Responses, and Evaluations.  
- **Prompt Evaluation Framework** → Describes how rubric-based and AI-driven evaluations are applied in practice.  

---

## 📝 Notes

- **Solid borders** = MVP (currently implemented)  
- **Dashed borders** = Future (planned functionality)  
- This diagram is a **living reference**. It will evolve as features like **similarity scoring**, **AI evaluation**, and **bias tracking** are implemented.
